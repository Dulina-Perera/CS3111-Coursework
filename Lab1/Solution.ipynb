{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the Deprecation Warnings.\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Load in the necessary libraries.\n",
    "import eli5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset.\n",
    "df_train = pd.read_csv('Resources/train.csv')\n",
    "df_val = pd.read_csv('Resources/valid.csv')\n",
    "df_test = pd.read_csv('Resources/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a general overview of the dataset.\n",
    "display(df_train.head())\n",
    "display(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns with missing values.\n",
    "missing = df_train.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(missing)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns where more than 50% of the data is missing.\n",
    "df_train.dropna(axis='columns', inplace=True, thresh=len(df_train)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df_train.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(missing)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "display(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Removing Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.select_dtypes(include=['int64', 'float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The business context should govern how we define and react to outliers.\n",
    "# The meanings of our findings should be dictated by the underlying context, rather than the number itself.\n",
    "\n",
    "display(df_train.select_dtypes(include=['int', 'float']).columns)\n",
    "\n",
    "feature = 'last_pymnt_amnt'\n",
    "sns.boxplot(x=df_train[feature])\n",
    "q1 = df_train[feature].quantile(0.25)\n",
    "q3 = df_train[feature].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "display(lower_bound, upper_bound)\n",
    "num_values_outside_bounds = ((df_train[feature] < lower_bound) | (df_train[feature] > upper_bound)).sum()\n",
    "display(num_values_outside_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_features(df):\n",
    "#     # Scale numerical columns using MinMaxScaler, excluding the target column if it exists.\n",
    "#     scaler = MinMaxScaler()\n",
    "\n",
    "#     numerical_columns = df.select_dtypes(include=['int', 'float']).columns\n",
    "#     if 'loan_status' in numerical_columns:\n",
    "#         numerical_columns = numerical_columns.drop('loan_status')\n",
    "#     df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "\n",
    "# scale_features(df_train)\n",
    "# scale_features(df_val)\n",
    "# scale_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['term', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
       "       'home_ownership', 'verification_status', 'issue_d', 'pymnt_plan',\n",
       "       'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line',\n",
       "       'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d',\n",
       "       'application_type', 'hardship_flag', 'disbursement_method',\n",
       "       'debt_settlement_flag'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "      <th>issue_m</th>\n",
       "      <th>issue_y</th>\n",
       "      <th>earliest_cr_m</th>\n",
       "      <th>earliest_cr_y</th>\n",
       "      <th>last_pymnt_m</th>\n",
       "      <th>last_pymnt_y</th>\n",
       "      <th>last_credit_pull_m</th>\n",
       "      <th>last_credit_pull_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8100</td>\n",
       "      <td>8100</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.47</td>\n",
       "      <td>267.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.99</td>\n",
       "      <td>336.90</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9450</td>\n",
       "      <td>9450</td>\n",
       "      <td>9450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.67</td>\n",
       "      <td>321.47</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>1998</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>24975.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.49</td>\n",
       "      <td>897.43</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>1990</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>380.56</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172591</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.25</td>\n",
       "      <td>253.95</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172592</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.49</td>\n",
       "      <td>418.12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.89</td>\n",
       "      <td>938.57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.59</td>\n",
       "      <td>110.64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2004</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.32</td>\n",
       "      <td>361.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>1980</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172596 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  term  \\\n",
       "0      NaN        NaN       8100         8100           8100.0     1   \n",
       "1      NaN        NaN      10000        10000          10000.0     1   \n",
       "2      NaN        NaN       9450         9450           9450.0     1   \n",
       "3      NaN        NaN      25000        25000          24975.0     1   \n",
       "4      NaN        NaN      16000        16000          16000.0     0   \n",
       "...     ..        ...        ...          ...              ...   ...   \n",
       "172591 NaN        NaN       7000         7000           7000.0     1   \n",
       "172592 NaN        NaN      12500        12500          12500.0     1   \n",
       "172593 NaN        NaN      30000        30000          30000.0     1   \n",
       "172594 NaN        NaN       3500         3500           3500.0     1   \n",
       "172595 NaN        NaN      12000        12000          12000.0     1   \n",
       "\n",
       "        int_rate  installment  grade  sub_grade  ...  settlement_percentage  \\\n",
       "0          11.47       267.00      1          9  ...                    NaN   \n",
       "1          12.99       336.90      2         11  ...                    NaN   \n",
       "2          13.67       321.47      1          9  ...                    NaN   \n",
       "3          17.49       897.43      3         19  ...                    NaN   \n",
       "4          14.99       380.56      2         14  ...                    NaN   \n",
       "...          ...          ...    ...        ...  ...                    ...   \n",
       "172591     18.25       253.95      4         20  ...                    NaN   \n",
       "172592     12.49       418.12      1          9  ...                    NaN   \n",
       "172593      7.89       938.57      0          4  ...                    NaN   \n",
       "172594      8.59       110.64      0          4  ...                    NaN   \n",
       "172595      5.32       361.38      0          0  ...                    NaN   \n",
       "\n",
       "        settlement_term  issue_m  issue_y  earliest_cr_m  earliest_cr_y  \\\n",
       "0                   NaN        3     2016              3           2010   \n",
       "1                   NaN        5     2016              9           2005   \n",
       "2                   NaN       11     2013              8           1998   \n",
       "3                   NaN        6     2011             11           1990   \n",
       "4                   NaN        2     2015              6           2001   \n",
       "...                 ...      ...      ...            ...            ...   \n",
       "172591              NaN        5     2015              4           2012   \n",
       "172592              NaN        8     2014              9           2006   \n",
       "172593              NaN        6     2015              1           1999   \n",
       "172594              NaN        7     2016             10           2004   \n",
       "172595              NaN        3     2016              8           1980   \n",
       "\n",
       "        last_pymnt_m last_pymnt_y  last_credit_pull_m  last_credit_pull_y  \n",
       "0                  4         2016                   5                2018  \n",
       "1                  9         2016                   2                2017  \n",
       "2                  8         2014                   5                2018  \n",
       "3                  6         2014                   6                2014  \n",
       "4                  7         2017                   1                2018  \n",
       "...              ...          ...                 ...                 ...  \n",
       "172591            11         2016                   2                2019  \n",
       "172592             1         2016                   1                2019  \n",
       "172593             7         2018                  11                2018  \n",
       "172594            12         2017                   2                2019  \n",
       "172595             6         2016                   2                2019  \n",
       "\n",
       "[172596 rows x 148 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Display the categorical columns.\n",
    "display(df_train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "\n",
    "def encode_cat_cols(df):\n",
    "    # display(df['term'].value_counts())\n",
    "    df['term'] = df['term'].map({' 60 months': 0, ' 36 months': 1})\n",
    "\n",
    "    # display(df['grade'].value_counts())\n",
    "    mapping_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}\n",
    "    df['grade'] = df['grade'].map(mapping_dict)\n",
    "\n",
    "    # display(df['sub_grade'].value_counts())\n",
    "    mapping_dict = {\n",
    "        'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4,\n",
    "        'B1': 5, 'B2': 6, 'B3': 7, 'B4': 8, 'B5': 9,\n",
    "        'C1': 10, 'C2': 11, 'C3': 12, 'C4': 13, 'C5': 14,\n",
    "        'D1': 15, 'D2': 16, 'D3': 17, 'D4': 18, 'D5': 19,\n",
    "        'E1': 20, 'E2': 21, 'E3': 22, 'E4': 23, 'E5': 24,\n",
    "        'F1': 25, 'F2': 26, 'F3': 27, 'F4': 28, 'F5': 29,\n",
    "        'G1': 30, 'G2': 31, 'G3': 32, 'G4': 33, 'G5': 34\n",
    "    }\n",
    "    df['sub_grade'] = df['sub_grade'].map(mapping_dict)\n",
    "\n",
    "    # display(df['emp_title'].value_counts())\n",
    "    df['emp_title'] = df['emp_title'].str.lower()\n",
    "    df['emp_title'] = label_encoder.fit_transform(df['emp_title'])\n",
    "\n",
    "    # display(df['emp_length'].value_counts())\n",
    "    df['emp_length'] = df['emp_length'].str.replace(' years?', '', regex=True)\n",
    "    mapping_dict = {'< 1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10+': 10}\n",
    "    df['emp_length'] = df['emp_length'].map(mapping_dict).fillna(0).astype(int)\n",
    "\n",
    "    # display(df['home_ownership'].value_counts())\n",
    "    mapping_dict = {'OWN': 0, 'RENT': 1, 'MORTGAGE': 2, 'ANY': 4, 'OTHER': 4, 'NONE': 4}\n",
    "    df['home_ownership'] = df['home_ownership'].map(mapping_dict)\n",
    "\n",
    "    # display(df['verification_status'].value_counts())\n",
    "    mapping_dict = {'Verified': 0, 'Source Verified': 1, 'Not Verified': 2}\n",
    "    df['verification_status'] = df['verification_status'].map(mapping_dict)\n",
    "\n",
    "    # display(df['issue_d'].value_counts())\n",
    "    df[['issue_m', 'issue_y']] = df['issue_d'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['issue_m'] = df['issue_m'].map(mapping_dict)\n",
    "    df['issue_m'] = df['issue_m'].astype(int)\n",
    "    df['issue_y'] = df['issue_y'].astype(int)\n",
    "    df.drop(columns='issue_d', inplace=True)\n",
    "\n",
    "    # display(df['pymnt_plan'].value_counts())\n",
    "    mapping_dict = {'y': 0, 'n': 1}\n",
    "    df['pymnt_plan'] = df['pymnt_plan'].map(mapping_dict)\n",
    "\n",
    "    # display(df['purpose'].value_counts())\n",
    "    df['purpose'] = label_encoder.fit_transform(df['purpose'])\n",
    "\n",
    "    # display(df['title'].value_counts())\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    df['title'] = label_encoder.fit_transform(df['title'])\n",
    "\n",
    "    # display(df['zip_code'].value_counts())\n",
    "    df['zip_code'] = df['zip_code'].str.lower()\n",
    "    df['zip_code'] = label_encoder.fit_transform(df['zip_code'])\n",
    "\n",
    "    # display(df['addr_state'].value_counts())\n",
    "    df['addr_state'] = label_encoder.fit_transform(df['addr_state'])\n",
    "\n",
    "    # display(df['earliest_cr_line'].value_counts())\n",
    "    df[['earliest_cr_m', 'earliest_cr_y']] = df['earliest_cr_line'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['earliest_cr_m'] = df['earliest_cr_m'].map(mapping_dict)\n",
    "    df['earliest_cr_m'] = df['earliest_cr_m'].astype(int)\n",
    "    df['earliest_cr_y'] = df['earliest_cr_y'].astype(int)\n",
    "    df.drop(columns='earliest_cr_line', inplace=True)\n",
    "\n",
    "    # display(df['initial_list_status'].value_counts())\n",
    "    mapping_dict = {'f': 0, 'w': 1}\n",
    "    df['initial_list_status'] = df['initial_list_status'].map(mapping_dict)\n",
    "\n",
    "    # display(df['last_pymnt_d'].value_counts())\n",
    "    df[['last_pymnt_m', 'last_pymnt_y']] = df['last_pymnt_d'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['last_pymnt_m'] = df['last_pymnt_m'].map(mapping_dict)\n",
    "    df['last_pymnt_m'] = df['last_pymnt_m'].fillna(99)\n",
    "    df['last_pymnt_y'] = df['last_pymnt_y'].fillna('9999')\n",
    "    df['last_pymnt_m'] = df['last_pymnt_m'].astype(int)\n",
    "    df['last_pymnt_y'] = df['last_pymnt_y'].astype(int)\n",
    "    df.drop(columns='last_pymnt_d', inplace=True)\n",
    "\n",
    "    # display(df['last_credit_pull_d'].value_counts())\n",
    "    df[['last_credit_pull_m', 'last_credit_pull_y']] = df['last_credit_pull_d'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['last_credit_pull_m'] = df['last_credit_pull_m'].map(mapping_dict)\n",
    "    df['last_credit_pull_m'] = df['last_credit_pull_m'].fillna(0)\n",
    "    df['last_credit_pull_y'] = df['last_credit_pull_y'].fillna('0000')\n",
    "    df['last_credit_pull_m'] = df['last_credit_pull_m'].astype(int)\n",
    "    df['last_credit_pull_y'] = df['last_credit_pull_y'].astype(int)\n",
    "    df.drop(columns='last_credit_pull_d', inplace=True)\n",
    "\n",
    "    # display(df['application_type'].value_counts())\n",
    "    mapping_dict = {'Joint App': 0, 'Individual': 1}\n",
    "    df['application_type'] = df['application_type'].map(mapping_dict)\n",
    "\n",
    "    # display(df['hardship_flag'].value_counts())\n",
    "    mapping_dict = {'N': 0, 'Y': 1}\n",
    "    df['hardship_flag'] = df['hardship_flag'].map(mapping_dict)\n",
    "\n",
    "    # display(df['disbursement_method'].value_counts())\n",
    "    mapping_dict = {'DirectPay': 0, 'Cash': 1}\n",
    "    df['disbursement_method'] = df['disbursement_method'].map(mapping_dict)\n",
    "\n",
    "    # display(df['debt_settlement_flag'].value_counts())\n",
    "    mapping_dict = {'Y': 0, 'N': 1}\n",
    "    df['debt_settlement_flag'] = df['debt_settlement_flag'].map(mapping_dict)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "encode_cat_cols(df_train)\n",
    "encode_cat_cols(df_val)\n",
    "encode_cat_cols(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_pymnt_amnt', 'funded_amnt', 'total_rec_prncp', 'recoveries'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999623397993001\n"
     ]
    }
   ],
   "source": [
    "def train_xgboost_classifier(df, features, target):\n",
    "    # Initialize XGBoost classifier\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Train the classifier on the entire dataset\n",
    "    xgb_classifier.fit(df[features], df[target])\n",
    "\n",
    "    return xgb_classifier\n",
    "\n",
    "\n",
    "def select_features(df, target, feature_importance_threshold=0.01):\n",
    "    # Initialize XGBoost classifier for feature selection\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Train the classifier to select features based on importance scores\n",
    "    selector = SelectFromModel(xgb_classifier, threshold=feature_importance_threshold)\n",
    "    selector.fit(df.drop(target, axis=1), df[target])\n",
    "\n",
    "    # Get selected feature indices\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "    # # Get selected feature names\n",
    "    # selected_features = df.drop(target, axis=1).columns[selected_feature_indices]\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Predict on the dataset\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def save_predictions(df, selected_features, model, output_file='test.csv'):\n",
    "    # Subset the DataFrame with selected features\n",
    "    X_selected = df[selected_features]\n",
    "\n",
    "    # Predict on the dataset\n",
    "    y_pred = model.predict(X_selected)\n",
    "\n",
    "    # Create a new DataFrame with selected features and predicted target variable\n",
    "    df_with_predictions = X_selected.copy()\n",
    "    df_with_predictions['loan_status'] = y_pred\n",
    "\n",
    "    # Rearrange columns to have 'loan_status' as the first column\n",
    "    df_with_predictions = df_with_predictions[['loan_status'] + list(X_selected.columns)]\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    df_with_predictions.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "_df_train = df_train.copy()\n",
    "_df_val = df_val.copy()\n",
    "_df_test = df_test.copy()\n",
    "\n",
    "# Define the target variable\n",
    "target = 'loan_status'\n",
    "\n",
    "# Select features based on importance scores\n",
    "selected_features = select_features(df_train, target)\n",
    "display(selected_features)\n",
    "\n",
    "# Train XGBoost classifier\n",
    "model = train_xgboost_classifier(_df_train, selected_features, target)\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "# evaluate_model(model, df_val[selected_features], df_val[target])\n",
    "evaluate_model(model, _df_val[selected_features], _df_val[target])\n",
    "\n",
    "# Save predictions on test set\n",
    "save_predictions(_df_test, selected_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4649\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                total_rec_prncp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3443\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                funded_amnt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1413\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                recoveries\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                last_pymnt_amnt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                term\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the permutation importances.\n",
    "perm = PermutationImportance(model, random_state=1).fit(df_val[selected_features], df_val[target])\n",
    "display(eli5.show_weights(perm, feature_names=selected_features.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['term'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
