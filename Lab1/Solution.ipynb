{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the Deprecation Warnings.\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Load in the necessary libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataset.\n",
    "df_train = pd.read_csv('Resources/train.csv')\n",
    "df_val = pd.read_csv('Resources/valid.csv')\n",
    "df_test = pd.read_csv('Resources/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a general overview of the dataset.\n",
    "display(df_train.head())\n",
    "display(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns where more than 50% of the data is missing.\n",
    "df_train.dropna(axis='columns', inplace=True, thresh=len(df_train)/2)\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting and Removing Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.select_dtypes(include=['int64', 'float64']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The business context should govern how we define and react to outliers.\n",
    "# The meanings of our findings should be dictated by the underlying context, rather than the number itself.\n",
    "\n",
    "sns.boxplot(x=df_train['int_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Display the categorical columns.\n",
    "display(df_train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "\n",
    "def encode_cat_cols(df):\n",
    "    df['term'] = df['term'].map({'60 months': 0, '36 months': 1})\n",
    "\n",
    "    mapping_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}\n",
    "    df['grade'] = df['grade'].map(mapping_dict)\n",
    "\n",
    "    mapping_dict = {\n",
    "        'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4,\n",
    "        'B1': 5, 'B2': 6, 'B3': 7, 'B4': 8, 'B5': 9,\n",
    "        'C1': 10, 'C2': 11, 'C3': 12, 'C4': 13, 'C5': 14,\n",
    "        'D1': 15, 'D2': 16, 'D3': 17, 'D4': 18, 'D5': 19,\n",
    "        'E1': 20, 'E2': 21, 'E3': 22, 'E4': 23, 'E5': 24,\n",
    "        'F1': 25, 'F2': 26, 'F3': 27, 'F4': 28, 'F5': 29,\n",
    "        'G1': 30, 'G2': 31, 'G3': 32, 'G4': 33, 'G5': 34\n",
    "    }\n",
    "    df['sub_grade'] = df['sub_grade'].map(mapping_dict)\n",
    "\n",
    "    df['emp_title'] = df['emp_title'].str.lower()\n",
    "    df['emp_title'] = label_encoder.fit_transform(df['emp_title'])\n",
    "\n",
    "    df['emp_length'] = df['emp_length'].str.replace(' years?', '', regex=True)\n",
    "    mapping_dict = {'< 1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10+': 10}\n",
    "    df['emp_length'] = df['emp_length'].map(mapping_dict).fillna(0).astype(int)\n",
    "\n",
    "    mapping_dict = {'OWN': 0, 'RENT': 1, 'MORTGAGE': 2, 'ANY': 4, 'OTHER': 4, 'NONE': 4}\n",
    "    df['home_ownership'] = df['home_ownership'].map(mapping_dict)\n",
    "\n",
    "    mapping_dict = {'Verified': 0, 'Source Verified': 1, 'Not Verified': 2}\n",
    "    df['verification_status'] = df['verification_status'].map(mapping_dict)\n",
    "\n",
    "    df[['issue_m', 'issue_y']] = df['issue_d'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['issue_m'] = df['issue_m'].map(mapping_dict)\n",
    "    df['issue_m'] = df['issue_m'].astype(int)\n",
    "    df['issue_y'] = df['issue_y'].astype(int)\n",
    "    df.drop(columns='issue_d', inplace=True)\n",
    "\n",
    "    mapping_dict = {'y': 0, 'n': 1}\n",
    "    df['pymnt_plan'] = df['pymnt_plan'].map(mapping_dict)\n",
    "\n",
    "    df['purpose'] = label_encoder.fit_transform(df['purpose'])\n",
    "\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    df['title'] = label_encoder.fit_transform(df['title'])\n",
    "\n",
    "    df['zip_code'] = df['zip_code'].str.lower()\n",
    "    df['zip_code'] = label_encoder.fit_transform(df['zip_code'])\n",
    "\n",
    "    df['addr_state'] = label_encoder.fit_transform(df['addr_state'])\n",
    "\n",
    "    df[['earliest_cr_m', 'earliest_cr_y']] = df['earliest_cr_line'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['earliest_cr_m'] = df['earliest_cr_m'].map(mapping_dict)\n",
    "    df['earliest_cr_m'] = df['earliest_cr_m'].astype(int)\n",
    "    df['earliest_cr_y'] = df['earliest_cr_y'].astype(int)\n",
    "    df.drop(columns='earliest_cr_line', inplace=True)\n",
    "\n",
    "    mapping_dict = {'f': 0, 'w': 1}\n",
    "    df['initial_list_status'] = df['initial_list_status'].map(mapping_dict)\n",
    "\n",
    "    df[['last_pymnt_m', 'last_pymnt_y']] = df['last_pymnt_d'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['last_pymnt_m'] = df['last_pymnt_m'].map(mapping_dict)\n",
    "    df['last_pymnt_m'] = df['last_pymnt_m'].fillna(99)\n",
    "    df['last_pymnt_y'] = df['last_pymnt_y'].fillna('9999')\n",
    "    df['last_pymnt_m'] = df['last_pymnt_m'].astype(int)\n",
    "    df['last_pymnt_y'] = df['last_pymnt_y'].astype(int)\n",
    "    df.drop(columns='last_pymnt_d', inplace=True)\n",
    "\n",
    "    df[['last_credit_pull_m', 'last_credit_pull_y']] = df['last_credit_pull_d'].str.split('-', expand=True)\n",
    "    mapping_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "    df['last_credit_pull_m'] = df['last_credit_pull_m'].map(mapping_dict)\n",
    "    df['last_credit_pull_m'] = df['last_credit_pull_m'].fillna(0)\n",
    "    df['last_credit_pull_y'] = df['last_credit_pull_y'].fillna('0000')\n",
    "    df['last_credit_pull_m'] = df['last_credit_pull_m'].astype(int)\n",
    "    df['last_credit_pull_y'] = df['last_credit_pull_y'].astype(int)\n",
    "    df.drop(columns='last_credit_pull_d', inplace=True)\n",
    "\n",
    "    mapping_dict = {'Joint App': 0, 'Individual': 1}\n",
    "    df['application_type'] = df['application_type'].map(mapping_dict)\n",
    "\n",
    "    mapping_dict = {'N': 0, 'Y': 1}\n",
    "    df['hardship_flag'] = df['hardship_flag'].map(mapping_dict)\n",
    "\n",
    "    mapping_dict = {'DirectPay': 0, 'Cash': 1}\n",
    "    df['disbursement_method'] = df['disbursement_method'].map(mapping_dict)\n",
    "\n",
    "    mapping_dict = {'Y': 0, 'N': 1}\n",
    "    df['debt_settlement_flag'] = df['debt_settlement_flag'].map(mapping_dict)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "encode_cat_cols(df_train)\n",
    "encode_cat_cols(df_val)\n",
    "encode_cat_cols(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df):\n",
    "    # Scale numerical columns using MinMaxScaler, excluding the target column if it exists.\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    numerical_columns = df.select_dtypes(include=['int', 'float']).columns\n",
    "    if 'loan_status' in numerical_columns:\n",
    "        numerical_columns = numerical_columns.drop('loan_status')\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "\n",
    "scale_features(df_train)\n",
    "scale_features(df_val)\n",
    "scale_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_classifier(df_train, features, target):\n",
    "    # Initialize XGBoost classifier\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Train the classifier on the entire dataset\n",
    "    xgb_classifier.fit(df_train[features], df_train[target])\n",
    "\n",
    "    return xgb_classifier\n",
    "\n",
    "\n",
    "def select_features(df_train, target, feature_importance_threshold=0.01):\n",
    "    # Initialize XGBoost classifier for feature selection\n",
    "    xgb_classifier = XGBClassifier()\n",
    "\n",
    "    # Train the classifier to select features based on importance scores\n",
    "    selector = SelectFromModel(xgb_classifier, threshold=feature_importance_threshold)\n",
    "    selector.fit(df_train.drop(target, axis=1), df_train[target])\n",
    "\n",
    "    # Get selected feature indices\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = df_train.drop(target, axis=1).columns[selected_feature_indices]\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Predict on the dataset\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def save_predictions(df, selected_features, model, output_file='test.csv'):\n",
    "    # Subset the DataFrame with selected features\n",
    "    X_selected = df[selected_features]\n",
    "\n",
    "    # Predict on the dataset\n",
    "    y_pred = model.predict(X_selected)\n",
    "\n",
    "    # Create a new DataFrame with selected features and predicted target variable\n",
    "    df_with_predictions = X_selected.copy()\n",
    "    df_with_predictions['loan_status'] = y_pred\n",
    "\n",
    "    # Rearrange columns to have 'loan_status' as the first column\n",
    "    df_with_predictions = df_with_predictions[['loan_status'] + list(X_selected.columns)]\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    df_with_predictions.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "# Define the target variable\n",
    "target = 'loan_status'\n",
    "\n",
    "# Select features based on importance scores\n",
    "selected_features = select_features(df_train, target)\n",
    "display(selected_features)\n",
    "\n",
    "# Train XGBoost classifier\n",
    "model = train_xgboost_classifier(df_train, selected_features), target)\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "# evaluate_model(model, df_val[selected_features], df_val[target])\n",
    "evaluate_model(model, df_val[selected_features], df_val[target])\n",
    "\n",
    "# Save predictions on test set\n",
    "save_predictions(df_test, selected_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
